---
title: "STA304 - Fall 2022"
author: "Eric Zhu - 1005131368"
subtitle: "Assignment 1"
date: "21/09/2022"
output:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(openintro)
```


# Part 1

### Goal
This survey examines the preferences across user categories (where a user is defined as someone who actively interacts with a GPU frequently, e.g., through a scientific computing library) for specialized hardware preferences in GPUs. This includes examining the preferences of GPU capabilities across users like academics/datacentre users/professionals and consumers (who include those like gamers and hobbyists).

 
A Graphics Processing Unit is a microprocessor that is suited for certain kinds of computations. Fundamentally, a GPU is a SIMD device (simultaneous instruction multiple data) device that enables much faster computation of matrix heavy operations, e.g., computer graphics and certain kinds of numerical optimization algorithms (gradient descent). They were originally built to accelerate rasterization performance (2D image rendering) across computer rendering with GPU cores that performed much faster than CPU cores for rendering thanks to specialization (Caulfield). Regardless of their origins, traditional GPU cores have been fundamental to machine learning experimentation, scientific modelling, and entertainment. 

In recent years, GPUs have gotten more capabilities via specialized hardware for tasks like real-time ray tracing (simulating realistic lighting) and half-precision (16 bit) matrix math (Evanson). Consumers have found this to be of dubious value depending on their background and use cases, leading to discussions across the industry and community about what functions GPUs should prioritize (Ravenscraft). As the GPU market continues its strong growth, slated to become a 27 billion dollar market by 2027, the question over GPU functionality preferences also grows in importance and relevance. While there may be many preferences for GPU capabilities, the preferences we wish to focus on are based on the distinct hardware capabilities that are most relevant across consumer categories, i.e., GPU cores for rasterization/traditional compute capabilities, real-time ray-tracing hardware, and hardware for half-precision matrix math. Essentially, we are aiming to examine the question: what kind of GPU user wants what kind of GPU hardware? 


### Procedure

Fundamentally, our goal is to analyse the preferences of GPUs across the consumer categories, including a diverse set of users with wildly different use cases. Thus, our target population is simply the users of GPUs across these different categories, and specifically for this survey, we are looking at two aggregated categories (professionals and consumers). The frame population is dependent on the likely ways of distributing this survey. The easiest way of distributing this survey would be through online forums of GPU users. Other ways would have significant drawbacks. For example, distributing it through exit surveys after GPU purchasing would leave us a biased same from those who use GPUs but do not directly purchase or install them, e.g., academics who run experiments on GPUs. Or the other option of using customer data collected by "game optimization" software from the manufacturer (like GeForce Experience) would bias our sample given that it is generally uncommon for enterprise settings to install these apps (e.g., AWS does not install these) and would potentially lead to biases for certain GPU manufacturers. Since forums are targeted to a specific demographic, it would make the most sense for us to employ stratified random sampling as this strategy follows most naturally from targeted forums where we would distribute our survey as they naturally form self-selecting strata. This is advantageous over other sampling methods, namely cluster random sampling. This is because it is simply unfeasible to form representative clusters with online forums, i.e., forum membership is voluntary and forum topic is predetermined. In other words, there is no good way of getting lists of users from forums like Reddit where such information is private. Thus the only feasible way would be to scrape users who comment and post as those are the only two publicly available pieces of user information. Then we'd have to send those users messages about our survey (after forming clusters), which could introduce bias should we use them as our sample since users who post generally are more vocal or passionate about some subject. So cluster random sampling could introduce worrying sources of sample bias. While stratified random sampling is definitely the better option among others, the major downside is that members of certain strata may belong in many strata, e.g., it is reasonable to assume that there are overlaps between gamers and academics (perhaps some PhD student plays video games). This may introduce some sampling bias as we might over/under represent some groups; this is unavoidable even with a different sampling technique as this source of bias is inherent to the individual so this bias would still be present regardless of sampling technique. 

### Showcasing the survey.

Survey link: [https://forms.office.com/r/uqb23eNtc7](https://forms.office.com/r/uqb23eNtc7)

I chose the following three questions overall because the first two are representative of questions that would enter the models as covariates, while the third question would enter the model as a response variable.  

**Question 1: Estimated minutes per day of intensive GPU usage? Intensive usage could be an application like training Deep Learning models, running 3D graphics applications like games, and or rendering videos.** 

This question is meant to gather information measuring the participant's familiarity of GPUs. The logic here is that the longer a user uses a GPU for their specified use case (e.g., a deep learning researcher interfacing with GPU based deep learning libraries), the more familiar that user would be with GPUs and their capabilities. This is similar to the logic how we could reasonably conclude that a person is familiar the functionality of their laptop should they use it a lot. An inherent drawback to this question is that it doesn't ask directly about a user's perceived familiarity with GPUs (perhaps on some scale, e.g., 1 to 10), so it's a proxy for it. But this is done because perceived familiarity can be heavily biased by their own perception, so this provides a more absolute measure of familiarity with GPUs. Another potential drawback is that since we allow for any input, this question measures the estimated minutes on a continuous scale; perhaps a discrete scale could provide us with the ability to model this variable using random effects, but this was done because there's no good cutoff for each group. In other words, a cutoff would be misinformed and could possibly lead to skewed analysis.

**Question 2: What type of GPU do you usually use?**

Options: 
- Datacentre/HPC (Nvidia A series, AMD instinct)
- High end consumer (Nvidia xx80 (ti), Nvidia xx90(ti), AMD x800, x800xt, x900xt, etc..., e.g., Nvidia RTX 3080) 
- Midrange consumer (Nvidia xx70 (ti), Nvidia xx60(ti), AMD x700, x700xt, x600xt, etc..., e.g., Nvidia RTX 3070)
- Entry level consumer (Nvidia xx50 and below, AMD x500 and below,  e.g., Nvidia RTX 3050)


This question is meant to gather information measuring the effect on GPU capability preferences due to a user's hardware segmentation. In other words, we are looking to gather information on if using a certain kind of GPU would affect their preferences for GPU hardware capabilities because different "levels" of GPUs have different characteristics. The logic here is comparable to asking a car owner about their current car in a survey about car feature preferences. Additionally, a strong point is that the categorization of the options is based on industry standards. As in, the datacentre/HPC categorization and corresponding examples (Nvidia A series, AMD instinct) are based on how they are marketed by both companies. For the consumer options (last 3), those are based on search results/a listing from Best Buy, a major electronics retailer. This should mean that there is very little ambiguity for the survey taker in choosing their appropriate category since this categorization would be exactly the same categories GPU buyers are exposed to. However, the downside to this is that some users may not necessarily agree with these categories, so they may not choose to follow the examples in the parenthesis as stated in the four options.


**Question 3: On a 100 point scale (allowing for decimals and 50 being neutral), how important is traditional GPU cores in GPUs?** 

This question is meant to gather information on a user's preference for traditional GPU cores on a 100 point scale, which is the response variable for one of the models. This question is repeated three times for the three hardware categories, i.e., traditional GPU cores, ray-tracing hardware, and half-precision matrix math hardware. We allow for decimal values so that it is appropriate later to model the response with a continuous probability distribution. So this question is meant to be interpreted along side the other two, and this is a major strength over making the user choose a particular specialized hardware preference or even a ranking. Primarily, this will allow us to examine all three hardware categories independently should the same covariates affect the response variable differently for each hardware category, i.e., we can get separate effect size estimations for the same covariates but for different response variables. A drawback is that this scale is not rigorously defined, and is the most open ended question in the survey. This is because GPU users may not consider the same scale as the other users, e.g., $50$ may be neutral to some users but may indicate a slight preference to others. To remedy this I added the "and 50 being neutral" part of the question. Nonetheless, users will likely still consider the scale to be slightly different based on their own experiences. A discrete scale, e.g., categories of preferences, could have been better as it would be more rigorously defined (labeled categories), but there would still be some bias regardless since the source of bias is the individual's conception of the scale, i.e., how in favour they are for some hardware capability. 


\newpage

# Part 2

## Data

We are looking to simulate the data due to practical sampling constraints. We have a few main considerations: the demographics that we are look to simulate, and the effects stemming from the covariates we wish to measure. Ultimately, we are looking to measure the preferences of individuals, given their use cases, for three kinds of hardware in GPUs: GPU cores, ray-tracing hardware, and half-precision matrix math hardware. Since it is conceivable that certain variables from our survey, e.g., type of GPU user will affect the preferences on a group level, we will consider the data generation in a so-called hierarchical manner. For example, 

```{r, include = FALSE}

# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you). 

# You may need additional chunks, in case you want to include some of the cleaning output.

```

<Type here a summary of the cleaning process.>

<Include a description of the important variables.> 

```{r, include=FALSE}

# Use this to calculate some summary measures. 

```


<Include a description of the numerical summaries. Remember you can use `r ` to use inline R code.>




```{r, echo = TRUE}

# Use this to create some plots. 

```

<Include a clear description of the plot(s). I would recommend one paragraph for each plot.> 

All analysis for this report was programmed using `R version 4.0.2`. 


## Methods

Our analysis will consist of mixed effects models that separately measure the preference for rasterization, ray-tracing, and half-precision matrix math hardware. In particular, we will have three models using the same model specification, but just measuring different response variables. So we will have a model for each one of the preferences for rasterization, ray-tracing, and half-precision matrix math hardware. We do this since each of these variables is a real valued variable on the interval $[0, 100]$. We will specifically model the response variable using a generalized linear mixed effects model, where the response is given as a truncated normal distribution. This is because the response variable is constrained to the interval $[0,100]$. 

$$ include.your.mathematical.model.here.if.you.have.some.math.to.show $$

<Here you should describe the CI. Here is an example with a citation:>

I will invoke a non-parametric bootstrap [2] to derive the 95\% confidence interval (CI) for the mean age of students in STA304.





## Results 


```{r, include = FALSE}
library(GLMMadaptive)
```
```{r, include = F}

```

<Here you could present your results. You may want to put them into a well formatted table. Be sure that there is some text describing the results.>


<Note: Alternatively you can use the `knitr::kable` function to create a well formatted table from your code. See here: [https://rmarkdown.rstudio.com/lesson-7.html](https://rmarkdown.rstudio.com/lesson-7.html). If you do this, be sure to include this in the bibliography [3].>



## Bibliography

1. Evanson, Nick. “Explainer: What Are Tensor Cores?” TechSpot, TechSpot, 27 July 2020, https://www.techspot.com/article/2049-what-are-tensor-cores/. 
2. Ravenscraft, Eric. “Should Anyone Actually Care about Ray Tracing?” Wired, Conde Nast, 3 Mar. 2021, https://www.wired.com/story/should-anyone-actually-care-about-ray-tracing/. 
3. Caulfield, Brian. “CPU vs GPU: What's the Difference?” NVIDIA Blog, 23 June 2022, https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/. 


\newpage

## Appendix


Here is a glimpse of the data set simulated/surveyed:

```{r, echo = FALSE}

# glimpse(my_data)

```




